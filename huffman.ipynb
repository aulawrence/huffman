{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from queue import PriorityQueue, Empty\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class BitList(object):\n",
    "    def __init__(self):\n",
    "        self.acc = bytearray()\n",
    "        self.tmp = \"\"\n",
    "        self.sealed = False\n",
    "        \n",
    "    def extend(self, bits):\n",
    "        assert not self.sealed\n",
    "        self.tmp += bits\n",
    "        while len(self.tmp) >= 8:\n",
    "            self.acc.append(int(self.tmp[:8], base=2))\n",
    "            self.tmp = self.tmp[8:]\n",
    "            \n",
    "    def seal(self):\n",
    "        assert not self.sealed\n",
    "        if self.tmp:\n",
    "            end_byte_len = len(self.tmp)\n",
    "            self.tmp += \"0000000\"\n",
    "            self.acc.append(int(self.tmp[:8], base=2))\n",
    "        else:\n",
    "            end_byte_len = 8\n",
    "        self.acc.append(end_byte_len)\n",
    "        self.sealed = True\n",
    "\n",
    "    def generator(self):\n",
    "        assert self.sealed\n",
    "        endbyte_len = self.acc[-1]\n",
    "        assert 0 < endbyte_len <= 8\n",
    "        for c in self.acc[:-2]:\n",
    "            for b in \"{:>08s}\".format(bin(c)[2:]):\n",
    "                yield b\n",
    "        c = self.acc[-2]\n",
    "        for b in \"{:>08s}\".format(bin(c)[2:])[:endbyte_len]:\n",
    "            yield b\n",
    "            \n",
    "    @staticmethod\n",
    "    def frombytes(b):\n",
    "        res = BitList()\n",
    "        res.acc = b\n",
    "        res.sealed = True\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     96
    ]
   },
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, left, right):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        if isinstance(self, Leaf) and isinstance(other, Leaf):\n",
    "            return self.value < other.value\n",
    "        elif isinstance(self, Leaf):\n",
    "            return True\n",
    "        elif isinstance(other, Leaf):\n",
    "            return False\n",
    "        else:\n",
    "            if self.left < other.left:\n",
    "                return True\n",
    "            elif self.left == other.left:\n",
    "                return self.right < other.right\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "    def __le__(self, other):\n",
    "        if isinstance(self, Leaf) and isinstance(other, Leaf):\n",
    "            return self.value <= other.value\n",
    "        elif isinstance(self, Leaf):\n",
    "            return True\n",
    "        elif isinstance(other, Leaf):\n",
    "            return False\n",
    "        else:\n",
    "            if self.left < other.left:\n",
    "                return True\n",
    "            elif self.left == other.left:\n",
    "                return self.right <= other.right\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(self, Leaf) and isinstance(other, Leaf):\n",
    "            return self.value == other.value\n",
    "        elif isinstance(self, Leaf):\n",
    "            return False\n",
    "        elif isinstance(other, Leaf):\n",
    "            return False\n",
    "        else:\n",
    "            return self.left == other.left and self.right == other.right\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.left) ^ hash(self.right)\n",
    "    \n",
    "    def bin(self):\n",
    "        data, bit_list = self._bin(bytearray(), BitList())\n",
    "        bit_list.seal()\n",
    "        return data, bit_list.acc\n",
    "\n",
    "    def _bin(self, data, bit_list):\n",
    "        bit_list.extend(\"0\")\n",
    "        data, bit_list = self.left._bin(data, bit_list)\n",
    "        data, bit_list = self.right._bin(data, bit_list)\n",
    "        return data, bit_list\n",
    "\n",
    "    @staticmethod\n",
    "    def reconstruct(step, data, structure):\n",
    "        root = None\n",
    "        stack = []\n",
    "        j = 0\n",
    "        for i in BitList.frombytes(structure).generator():\n",
    "            if i == \"0\":\n",
    "                newnode = Node(None, None)\n",
    "                if stack:\n",
    "                    prev = stack[-1]\n",
    "                    if prev.left is None:\n",
    "                        prev.left = newnode\n",
    "                    else:\n",
    "                        assert prev.right is None\n",
    "                        prev.right = newnode\n",
    "                else:\n",
    "                    root = newnode\n",
    "                stack.append(newnode)\n",
    "            else:\n",
    "                assert i == \"1\"\n",
    "                newnode = Leaf(bytes(data[j: j+step]))\n",
    "                j += step\n",
    "                if stack:\n",
    "                    prev = stack[-1]\n",
    "                    if prev.left is None:\n",
    "                        prev.left = newnode\n",
    "                    else:\n",
    "                        assert prev.right is None\n",
    "                        prev.right = newnode\n",
    "                        while stack and stack[-1].right is not None:\n",
    "                            stack.pop()\n",
    "                else:\n",
    "                    root = newnode\n",
    "        assert not stack\n",
    "        assert j == len(data)\n",
    "        return root\n",
    "\n",
    "class Leaf(Node):\n",
    "    def __init__(self, i):\n",
    "        self.value = i\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.value)\n",
    "\n",
    "    def _bin(self, data, bit_list):\n",
    "        data.extend(self.value)\n",
    "        bit_list.extend(\"1\")\n",
    "        return data, bit_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     5
    ]
   },
   "outputs": [],
   "source": [
    "def pad(s, n):\n",
    "    if len(s) < n:\n",
    "        return s + b\"\\x00\" * (n - len(s))\n",
    "    return s\n",
    "\n",
    "def tokenize(s, n):\n",
    "    for i in range(0, len(s)//n):\n",
    "        yield s[n*i:n*(i+1)]\n",
    "    if len(s) % n != 0:\n",
    "        yield pad(s[n*(len(s)//n):], n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     7
    ]
   },
   "outputs": [],
   "source": [
    "def encode(tokenized_text, key):\n",
    "    cipher_text = BitList()\n",
    "    for c in tokenized_text:\n",
    "        cipher_text.extend(key[c])\n",
    "    cipher_text.seal()\n",
    "    return cipher_text.acc\n",
    "\n",
    "def decode(cipher_text, node):\n",
    "    text = bytearray()\n",
    "    curr = node\n",
    "    for b in BitList.frombytes(cipher_text).generator():\n",
    "        if b == \"0\":\n",
    "            curr = curr.left\n",
    "        else:\n",
    "            assert b == \"1\"\n",
    "            curr = curr.right\n",
    "        if isinstance(curr, Leaf):\n",
    "            text.extend(curr.value)\n",
    "            curr = node\n",
    "    return bytes(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     17
    ]
   },
   "outputs": [],
   "source": [
    "def huffman(tokens):\n",
    "    dt = defaultdict(int)\n",
    "    for k in tokens:\n",
    "        dt[k] += 1\n",
    "    q = PriorityQueue()\n",
    "    for k, v in dt.items():\n",
    "        q.put((v, Leaf(k)))\n",
    "    try:\n",
    "        while True:\n",
    "            ai, a = q.get()\n",
    "            bi, b = q.get_nowait()\n",
    "            c = Node(a, b)\n",
    "            q.put((ai+bi, c))\n",
    "    except Empty:\n",
    "        pass\n",
    "    return a\n",
    "\n",
    "def get_key(root_node):\n",
    "    key = {}\n",
    "    def add_to_key(key, node, stack=[]):\n",
    "        if isinstance(node, Leaf):\n",
    "            key[node.value] = \"\".join(stack)\n",
    "        else:\n",
    "            stack.append(\"0\")\n",
    "            add_to_key(key, node.left, stack)\n",
    "            stack.pop()\n",
    "            stack.append(\"1\")\n",
    "            add_to_key(key, node.right, stack)\n",
    "            stack.pop()\n",
    "    add_to_key(key, root_node)\n",
    "    return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def stat(src, i):\n",
    "    dt = defaultdict(int)\n",
    "    for k in tokenize(src, i):\n",
    "        dt[k] += 1\n",
    "    key = get_key(huffman(tokenize(src, i)))\n",
    "    dt2 = {}\n",
    "    for k in tokenize(src, i):\n",
    "        dt2[k] = (dt[k], len(key[k]))\n",
    "    arr = np.array(list(dt2.values()))\n",
    "    freq = arr[:, 0]\n",
    "    theo_prob = freq / sum(freq)\n",
    "    huff_prob = 2. ** -arr[:, 1]\n",
    "    return {\n",
    "        \"i\": i,\n",
    "        \"entropy\": sum(freq * -np.log2(theo_prob)),\n",
    "        \"document_size\": sum(freq * -np.log2(huff_prob)),\n",
    "        \"tree_data_size\": len(dt)*len(k)*8,\n",
    "        \"tree_rep_size\": 2*len(dt)-1,\n",
    "        \"total_size\": sum(freq * -np.log2(huff_prob)) + len(dt)*len(k)*8 + 2*len(dt)-1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/input1.txt\", \"rb\") as f:\n",
    "    src = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([stat(src, i) for i in range(1, 15)])\n",
    "df_melt = df.melt(id_vars=\"i\", value_name=\"size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "( ggplot(data=df_melt)\n",
    " +geom_point(aes(x=\"i\", y=\"size\", color=\"variable\"))\n",
    " +geom_hline(yintercept=len(src)*8, color=\"black\") # original\n",
    " +annotate(\"label\", 15, len(src)*8, label=\"Orig\", size=8)\n",
    " +geom_hline(yintercept=1200*8, color=\"orange\") # zip\n",
    " +annotate(\"label\", 15, 1200*8, label=\"Zip\", size=8)\n",
    " +scale_x_continuous(breaks=range(15), minor_breaks=())\n",
    " +ggtitle(\"Bits Required to Represent input1.txt using Huffman Coding\")\n",
    " +xlab(\"Token Size (bytes)\")\n",
    " +ylab(\"Representation Size (bits)\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/input2.txt\", \"rb\") as f:\n",
    "    src2 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame([stat(src2, i) for i in range(1, 15)])\n",
    "df2_melt = df2.melt(id_vars=\"i\", value_name=\"size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "( ggplot(data=df2_melt)\n",
    " +geom_point(aes(x=\"i\", y=\"size\", color=\"variable\"))\n",
    " +geom_hline(yintercept=len(src2)*8, color=\"black\") # original\n",
    " +annotate(\"label\", 15, len(src2)*8, label=\"Orig\", size=8)\n",
    " +geom_hline(yintercept=17600*8, color=\"orange\") # zip\n",
    " +annotate(\"label\", 15, 17600*8, label=\"Zip\", size=8)\n",
    " +scale_x_continuous(breaks=range(15), minor_breaks=())\n",
    " +ggtitle(\"Bits Required to Represent input2.txt using Huffman Coding\")\n",
    " +xlab(\"Token Size (bytes)\")\n",
    " +ylab(\"Representation Size (bits)\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/input3.txt\", \"rb\") as f:\n",
    "    src3 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame([stat(src3, i) for i in range(1, 15)])\n",
    "df3_melt = df3.melt(id_vars=\"i\", value_name=\"size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "( ggplot(data=df3_melt)\n",
    " +geom_point(aes(x=\"i\", y=\"size\", color=\"variable\"))\n",
    " +geom_hline(yintercept=len(src3)*8, color=\"black\") # original\n",
    " +annotate(\"label\", 15, len(src3)*8, label=\"Orig\", size=8)\n",
    " +geom_hline(yintercept=56200*8, color=\"orange\") # zip\n",
    " +annotate(\"label\", 15, 56200*8, label=\"Zip\", size=8)\n",
    " +scale_x_continuous(breaks=range(15), minor_breaks=())\n",
    " +ggtitle(\"Bits Required to Represent input3.txt using Huffman Coding\")\n",
    " +xlab(\"Token Size (bytes)\")\n",
    " +ylab(\"Representation Size (bits)\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "root_node = huffman(tokenize(src3, 2))\n",
    "data, structure = root_node.bin()\n",
    "root_reconstruct = Node.reconstruct(2, data, structure)\n",
    "assert root_node == root_reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = get_key(root_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip = encode(tokenize(src3, 2), key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = decode(cip, root_reconstruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output/output3.txt\", \"wb\") as f:\n",
    "    f.write(cip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output/decode3.txt\", \"wb\") as f:\n",
    "    f.write(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cip)*8, len(data)*8, len(structure)*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.iloc[1, :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
